{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as grb\n",
    "import analyzer\n",
    "\n",
    "from gurobipy import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "from elina_box import *\n",
    "from elina_interval import *\n",
    "from elina_abstract0 import *\n",
    "from elina_manager import *\n",
    "from elina_dimension import *\n",
    "from elina_scalar import *\n",
    "from elina_interval import *\n",
    "from elina_linexpr0 import *\n",
    "from elina_lincons0 import *\n",
    "import ctypes\n",
    "from ctypes.util import find_library\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_solver(inf, sup, weights, biases, numlayers,output,start,label):\n",
    "\n",
    "    opt_model = Model(\"mip1\")\n",
    "    max_model = Model(\"max\")\n",
    "\n",
    "  \n",
    "    for layer in range(start,numlayers):\n",
    "        #j is the index of the current output node optimized\n",
    "       \n",
    "        if (layer+1!=nn.numlayer):\n",
    "            layer_weights = nn.weights[layer+1]\n",
    "            layer_biases = nn.biases[layer+1]\n",
    "            #print(\"biases_layer_{}\".format(layer))\n",
    "            #print(layer_biases)\n",
    "\n",
    "            np.ascontiguousarray(layer_weights, dtype=np.double)\n",
    "            np.ascontiguousarray(layer_biases, dtype=np.double)\n",
    "\n",
    "            num_out_pixels = len(layer_biases)\n",
    "            num_in_pixels = len(layer_weights[0])\n",
    "            \n",
    "        else:\n",
    "            num_out_pixels = 10\n",
    "            num_in_pixels = 10\n",
    "        set_I = range(num_in_pixels) \n",
    "        set_J = range(num_out_pixels)\n",
    "        #print(inf[layer])\n",
    "        #print(sup[layer])\n",
    "\n",
    "\n",
    "        set_optimize_I = [i for i in set_I if inf[layer][i]<0 and sup[layer][i]>0] #boxes optimized by linear program\n",
    "        set_zeros_I = [i for i in set_I if inf[layer][i]<=0 and sup[layer][i]<=0]  #boxes taken to [0,0] by relu \n",
    "        set_leave_I = [i for i in set_I if inf[layer][i]>0 and sup[layer][i]>0] #boxes left as before relu    \n",
    "        \n",
    "        lambda_ = [0]*num_in_pixels\n",
    "        for i in set_optimize_I:\n",
    "            lambda_[i]=(sup[layer][i]/(sup[layer][i]-inf[layer][i]))\n",
    "\n",
    "        mu = [0]*num_in_pixels\n",
    "        for i in set_optimize_I:\n",
    "            mu[i]=((-1)*(sup[layer][i]*inf[layer][i])/(sup[layer][i]-inf[layer][i]))\n",
    "        \n",
    "\n",
    "        #---------------------------------------\n",
    "        #MINIMIZATION\n",
    "\n",
    "        \n",
    "        #opt_model.setParam('OutputFlag', False)\n",
    "        h_i_vars  = opt_model.addVars(num_in_pixels, lb=inf[layer], ub=sup[layer], name='h{0},'.format(layer))\n",
    "\n",
    "        if(layer!=start):\n",
    "            constraints = {i: opt_model.addConstr(lhs=objective[i],sense=GRB.EQUAL,rhs=h_i_vars[i],\n",
    "                                                 name=\"prev_constraint_{0}\".format(i)) for i in set_I}\n",
    "        \n",
    "        relu_h_i_vars  = opt_model.addVars(num_in_pixels, name='relu_h{0},'.format(layer))\n",
    "        \n",
    "    \n",
    "        \n",
    "            # Set objective sum over i wji*relu_h_is\n",
    "        if (layer+1!=numlayers):\n",
    "            objective = [grb.quicksum(layer_weights[j][i] * relu_h_i_vars[i] for i in set_I) + layer_biases[j]\n",
    "                         for j in set_J]\n",
    "        else: \n",
    "            objective = [relu_h_i_vars[i]*1 for i in set_I]\n",
    "        \n",
    "   \n",
    "\n",
    "            # for minimization\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.LESS_EQUAL,\n",
    "                                               rhs=lambda_[i] * h_i_vars[i] + mu[i], \n",
    "                                               name=\"constraint_lq_{0},{1}\".format(layer,i))\n",
    "                       for i in set_optimize_I}\n",
    "\n",
    "            # >= constraints\n",
    "        constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=0, \n",
    "                                               name=\"constraint_zero_{0},{1}\".format(layer,i))\n",
    "                       for i in set_optimize_I}\n",
    "\n",
    "        # >= constraints\n",
    "        constraints = {i :opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=h_i_vars[i], \n",
    "                                              name=\"constraint_grq_{0},{1}\".format(layer,i)) for i in set_optimize_I}\n",
    "\n",
    "        # == constraints\n",
    "        constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=h_i_vars[i],\n",
    "                                               name=\"constraint_{0},{1}\".format(layer,i)) \n",
    "                       for i in set_leave_I}\n",
    "\n",
    "        constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=0,\n",
    "                                               name=\"constraint_{0},{1}\".format(layer,i)) \n",
    "                      for i in set_zeros_I}\n",
    "        \n",
    "        \n",
    "       # print([objective[0].getCoeff(i) for i in range(objective[0].size())]) \n",
    "       # print([objective[0].getVar(i) for i in range(objective[0].size())])\n",
    "\n",
    "       # print(objective[0].getConstant())\n",
    "\n",
    "        \n",
    "\n",
    "        '''\n",
    "        #-------------------------------------------------\n",
    "        #MAXIMIZATION  \n",
    "\n",
    "        h_i_vars  = max_model.addVars(num_in_pixels, lb=inf[layer], ub=sup[layer], name='h{0},'.format(layer))\n",
    "       \n",
    "        if(layer):\n",
    "            constraints = {i: max_model.addConstr(lhs=objective_2[i],sense=GRB.EQUAL,rhs=h_i_vars[i],\n",
    "                                   name=\"prev_constraint_{0}\".format(i)) for i in set_I}\n",
    "\n",
    "        relu_h_i_vars  = max_model.addVars(num_in_pixels, name='relu_h{0},'.format(layer))\n",
    "       \n",
    "\n",
    "\n",
    "            # Set objective sum over i wji*relu_h_is\n",
    "        if (layer!=layerno):\n",
    "            objective_2 = [grb.quicksum(layer_weights[j][i] * relu_h_i_vars[i] for i in set_I) + layer_biases[j]\n",
    "                         for j in set_J]\n",
    "        else:\n",
    "            objective_2 = [relu_h_i_vars[i]*1 for i in set_I]\n",
    "\n",
    "\n",
    "\n",
    "        constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.LESS_EQUAL,\n",
    "                                               rhs=lambda_[i] * h_i_vars[i] + mu[i], \n",
    "                                               name=\"constraint_lq_{0},{1}\".format(layer,i))\n",
    "                       for i in set_optimize_I}\n",
    "\n",
    "            # >= constraints\n",
    "        constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=0, \n",
    "                                               name=\"constraint_zero_{0},{1}\".format(layer,i))\n",
    "                       for i in set_optimize_I}\n",
    "\n",
    "        # >= constraints\n",
    "        constraints = {i :max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=h_i_vars[i], \n",
    "                                              name=\"constraint_grq_{0},{1}\".format(layer,i)) for i in set_optimize_I}\n",
    "\n",
    "        # == constraints\n",
    "        constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=h_i_vars[i],\n",
    "                                               name=\"constraint_{0},{1}\".format(layer,i)) \n",
    "                       for i in set_leave_I}\n",
    "\n",
    "        constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=0,\n",
    "                                               name=\"constraint_{0},{1}\".format(layer,i)) \n",
    "                      for i in set_zeros_I}\n",
    "        \n",
    "        '''\n",
    "    if (numlayers != nn.numlayer):\n",
    "        opt_model.setObjective(objective[output], GRB.MINIMIZE)\n",
    "        opt_model.setParam('OutputFlag', False)\n",
    "       # opt_model.write('out1_min.mps')\n",
    "        opt_model.optimize()\n",
    "       # opt_model.computeIIS()\n",
    "\n",
    "      #  opt_model.write('out1.ilp')\n",
    "        h_j_min = opt_model.objVal\n",
    "        \n",
    "        opt_model.setObjective(objective[output],GRB.MAXIMIZE)\n",
    "\n",
    "        opt_model.optimize()\n",
    "        #max_model.computeIIS()\n",
    "        #max_model.write('out_max.mps')\n",
    "        #max_model.write('out1.ilp')\n",
    "        \n",
    "        h_j_max = opt_model.objVal\n",
    "\n",
    "        return h_j_min, h_j_max\n",
    "    else:\n",
    "        opt_model.setObjective(objective[label]-objective[output],GRB.MINIMIZE)\n",
    "        opt_model.setParam('OutputFlag', False)\n",
    "        opt_model.optimize()\n",
    "        value = opt_model.objVal\n",
    "        return value , 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../mnist_nets/mnist_relu_6_50.txt', 'r') as netfile:\n",
    "    netstring = netfile.read()\n",
    "verified = 0\n",
    "not_verified = 0\n",
    "fileno = 0\n",
    "\n",
    "extimes = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_nr: 0\n",
      "Total Execution time: 0s\n",
      "Academic license - for non-commercial use only\n",
      "38.656891107559204\n",
      "Verified: 1\n",
      "Not-Verified: 0\n",
      "Avg time: 38.656891107559204s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"../mnist_images/*\"):\n",
    "    if (fileno%10==0):\n",
    "        print(\"File_nr: {}\".format(fileno))\n",
    "        print(\"Total Execution time: {}s\".format(sum(extimes)))\n",
    "    fileno +=1\n",
    "    if (fileno == 20 and False):\n",
    "        break\n",
    "    not_verified_flag = False\n",
    "\n",
    "    with open(file, 'r') as specfile:\n",
    "        specstring = specfile.read()\n",
    "\n",
    "    x0_low, x0_high = analyzer.parse_spec(specstring)\n",
    "    label = x0_low[0].astype(int)\n",
    "\n",
    "\n",
    "    LB_N0, UB_N0 = analyzer.get_perturbed_image(x0_low,0.01)\n",
    "\n",
    "    nn = analyzer.parse_net(netstring)\n",
    "    nn.ffn_counter=0\n",
    "\n",
    "    start_time = time.time()\n",
    "    num_pixels = len(LB_N0)\n",
    "    man = elina_box_manager_alloc()\n",
    "    itv = elina_interval_array_alloc(num_pixels)\n",
    "    for i in range(num_pixels):\n",
    "        elina_interval_set_double(itv[i],LB_N0[i],UB_N0[i]) # specify itv[i]=[lb,ub] \n",
    "    ### Perform the box approximation for the first layer\n",
    "    ## construct input abstraction\n",
    "    element = elina_abstract0_of_box(man, 0, num_pixels, itv)\n",
    "    elina_interval_array_free(itv,num_pixels)\n",
    "    myinf = []\n",
    "    mysup = []\n",
    "    mylayer=5\n",
    "    stepsize=4\n",
    "    start = 0\n",
    "    mid = stepsize\n",
    "    stop = stepsize\n",
    "    for layerno in range(nn.numlayer):\n",
    "\n",
    "        weights = nn.weights[nn.ffn_counter]\n",
    "        biases = nn.biases[nn.ffn_counter]\n",
    "        dims = elina_abstract0_dimension(man,element)\n",
    "        num_in_pixels = dims.intdim + dims.realdim\n",
    "        num_out_pixels = len(weights)\n",
    "\n",
    "        dimadd = elina_dimchange_alloc(0,num_out_pixels)    \n",
    "        for i in range(num_out_pixels):\n",
    "            dimadd.contents.dim[i] = num_in_pixels\n",
    "        elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "        elina_dimchange_free(dimadd)\n",
    "        np.ascontiguousarray(weights, dtype=np.double)\n",
    "        np.ascontiguousarray(biases, dtype=np.double)\n",
    "        var = num_in_pixels\n",
    "\n",
    "        # handle affine layer\n",
    "        for i in range(num_out_pixels):\n",
    "            tdim= ElinaDim(var)\n",
    "            linexpr0 = analyzer.generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "            element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "            var+=1\n",
    "\n",
    "        dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "        for i in range(num_in_pixels):\n",
    "            dimrem.contents.dim[i] = i\n",
    "        elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "        elina_dimchange_free(dimrem)\n",
    "\n",
    "        dims = elina_abstract0_dimension(man,element)\n",
    "\n",
    "\n",
    "        # get bounds for each output neuron\n",
    "        bounds = elina_abstract0_to_box(man,element)\n",
    "        sup = [bounds[i].contents.sup.contents.val.dbl for i in range(num_out_pixels)]\n",
    "        inf = [bounds[i].contents.inf.contents.val.dbl for i in range(num_out_pixels)]\n",
    "        myinf.append(inf)\n",
    "        mysup.append(sup)\n",
    "        #print(\"------bounds_layer{}-------\".format(layerno))\n",
    "        #for (low,high) in zip(inf,sup):\n",
    "        #    print([low,high])\n",
    "\n",
    "\n",
    "        # handle ReLU layer\n",
    "      #  print(nn.layertypes[layerno])\n",
    "        if(nn.layertypes[layerno]=='ReLU'):\n",
    "           element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "        nn.ffn_counter+=1\n",
    "        #non overlaping\n",
    "        #if ((layerno+1)%stepsize==0):\n",
    "        #overlaping\n",
    "        if(layerno+1>=stepsize):\n",
    "            rnd = range(0,num_out_pixels)\n",
    "            \n",
    "            bounds = elina_abstract0_to_box(man,element)\n",
    "            sup = [bounds[i].contents.sup.contents.val.dbl for i in range(num_out_pixels)]\n",
    "            inf = [bounds[i].contents.inf.contents.val.dbl for i in range(num_out_pixels)]\n",
    "            if (not stop == nn.numlayer and False):\n",
    "                rnd = np.random.permutation(num_out_pixels)\n",
    "                rnd = rnd[0:num_out_pixels//2]\n",
    "                \n",
    "    \n",
    "           # print(\"_------gurobi------\")\n",
    "            for i in rnd:\n",
    "                \n",
    "                if (stop == nn.numlayer):\n",
    "                    low, high = linear_solver(myinf,mysup,nn.weights,nn.biases,stop,i,start,label)\n",
    "                    if (low<0):\n",
    "                        not_verified_flag = True\n",
    "                        not_verified += 1\n",
    "                        break\n",
    "                \n",
    "                else:\n",
    "                    low, high = linear_solver(myinf,mysup,nn.weights,nn.biases,stop,i,start,label)\n",
    "\n",
    "                    #create an array of two linear constraints\n",
    "                    lincons0_array = elina_lincons0_array_make(2)\n",
    "                    #Create a greater than or equal to inequality for the lower bound\n",
    "                    lincons0_array.p[0].constyp = c_uint(ElinaConstyp.ELINA_CONS_SUPEQ)\n",
    "                    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_SPARSE, 1)\n",
    "                    cst = pointer(linexpr0.contents.cst)\n",
    "                    #plug the lower bound “a” here\n",
    "                    elina_scalar_set_double(cst.contents.val.scalar, -low)\n",
    "                    linterm = pointer(linexpr0.contents.p.linterm[0])\n",
    "                    #plug the dimension “i” here\n",
    "                    linterm.contents.dim = ElinaDim(i)\n",
    "                    coeff = pointer(linterm.contents.coeff)\n",
    "                    elina_scalar_set_double(coeff.contents.val.scalar, 1)\n",
    "                    lincons0_array.p[0].linexpr0 = linexpr0\n",
    "                    #create a greater than or equal to inequality for the upper bound\n",
    "                    lincons0_array.p[1].constyp = c_uint(ElinaConstyp.ELINA_CONS_SUPEQ)\n",
    "                    linexpr0 = elina_linexpr0_alloc(ElinaLinexprDiscr.ELINA_LINEXPR_SPARSE, 1)\n",
    "                    cst = pointer(linexpr0.contents.cst)\n",
    "                    #plug the upper bound “b” here\n",
    "                    elina_scalar_set_double(cst.contents.val.scalar, high)\n",
    "                    linterm = pointer(linexpr0.contents.p.linterm[0])\n",
    "                    #plug the dimension “i” here\n",
    "                    linterm.contents.dim = ElinaDim(i)\n",
    "                    coeff = pointer(linterm.contents.coeff)\n",
    "                    elina_scalar_set_double(coeff.contents.val.scalar, -1)\n",
    "                    lincons0_array.p[1].linexpr0 = linexpr0\n",
    "                    #perform the intersection\n",
    "                    element = elina_abstract0_meet_lincons_array(man,True,element,lincons0_array)\n",
    "\n",
    "            if (start <= mid):\n",
    "                start += 1\n",
    "            if (start+1 == stop):\n",
    "            #start +=1\n",
    "                stop +=1\n",
    "    if (not not_verified_flag):\n",
    "        verified += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(end_time-start_time)\n",
    "    extimes.append(end_time-start_time)\n",
    "    print(\"Verified: {}\".format(verified))\n",
    "    print(\"Not-Verified: {}\".format(not_verified))\n",
    "    print(\"Avg time: {}s\".format(sum(extimes)/float(len(extimes))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-0.0, 3.087930445879932]\n",
    "[-0.0, 5.406580162398914]\n",
    "[0.7624031609543125, 8.851001925993886]\n",
    "[-0.0, 5.052544236985985]\n",
    "[-0.0, 1.3072560554657888]\n",
    "[-0.0, 2.692300956246867]\n",
    "[-0.0, 5.290572452729248]\n",
    "[-0.0, 2.800578426673901]\n",
    "[-0.0, 7.090457899704544]\n",
    "[-0.0, 1.411728745282659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-0.0, 5.747079887045851]\n",
    "[-0.0, 7.73025904062853]\n",
    "[-0.0, 11.140688565346176]\n",
    "[-0.0, 7.639942274360968]\n",
    "[-0.0, 5.062969481203944]\n",
    "[-0.0, 5.7883866800749155]\n",
    "[-0.0, 8.532428824942151]\n",
    "[-0.0, 5.166235700210473]\n",
    "[-0.0, 10.556580728614605]\n",
    "[-0.0, 4.949954653003554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------gurobi--------\")\n",
    "previous_time = time.time()\n",
    "start = previous_time\n",
    "mylayer = 1\n",
    "lower = []\n",
    "higher = []\n",
    "for i in range (0,10):\n",
    "    low, high = linear_solver(myinf,mysup,nn.weights,nn.biases,nn.numlayer,i,0,label)\n",
    "    #myinf[mylayer][i] = low\n",
    "    #mysup[mylayer][i] = high\n",
    "    lower.append(low)\n",
    "    higher.append(high)\n",
    "    if (i%10==0):\n",
    "        inter = time.time()\n",
    "        print(\"Neuron {}\".format(i))\n",
    "        print(inter-previous_time)\n",
    "        previous_time = inter\n",
    "    print([low,high])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9206643104553223\n",
    "[0.0, 4.471460461287338]\n",
    "[0.0, 7.9372877919069635]\n",
    "[5.762311094903923, 12.574372377555028]\n",
    "[0.0, 6.503944892416588]\n",
    "[0.0, 2.9280238135496317]\n",
    "[0.0, 4.0448538265482075]\n",
    "[0.0, 6.492572539410679]\n",
    "[0.0, 4.9538708360817685]\n",
    "[0.0, 5.286383777318398]\n",
    "[0.0, 1.581611571601533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array(lower)\n",
    "higher = np.array(high)\n",
    "lower = np.dot(lower,nn.weights[mylayer])+nn.biases[mylayer]\n",
    "higher = np.dot(higher,nn.weights[mylayer])+nn.biases[mylayer]\n",
    "\n",
    "for (low,high) in zip(myinf[mylayer],mysup[mylayer]):\n",
    "        print([low,high])\n",
    "        \n",
    "print(\"-----------------\")\n",
    "for i in range (0,10):\n",
    "    print([min(lower[i],higher[i]),max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------gurobi--------\")\n",
    "previous_time = time.time()\n",
    "start = previous_time\n",
    "mylayer = nn.numlayer\n",
    "for i in range (0,10):\n",
    "\n",
    "    low, high = linear_solver(myinf,mysup,nn.weights,nn.biases,mylayer,i,2,label)\n",
    "    if (i%10==0):\n",
    "        inter = time.time()\n",
    "        print(\"Neuron {}\".format(i))\n",
    "        print(inter-previous_time)\n",
    "        previous_time = inter\n",
    "    print([low,high])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mybounds = elina_abstract0_to_box(man, element)\n",
    "\n",
    "\n",
    "# handle ReLU layer\n",
    "if(nn.layertypes[layerno]=='ReLU'):\n",
    "  element = relu_box_layerwise(man,True,element,0, num_out_pixels)\n",
    "nn.ffn_counter+=1\n",
    "\n",
    "mybounds = elina_abstract0_to_box(man, element)\n",
    "\n",
    "for i in range(num_out_pixels):\n",
    "   inf = mybounds[i].contents.inf.contents.val.dbl\n",
    "   sup = mybounds[i].contents.sup.contents.val.dbl\n",
    "   #print(\"----boxRelu----\")\n",
    "   print([inf,sup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ffn_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = nn.weights[nn.ffn_counter]\n",
    "biases = nn.biases[nn.ffn_counter]\n",
    "dims = elina_abstract0_dimension(man,element)\n",
    "num_in_pixels = 10\n",
    "\n",
    "\n",
    "dimadd = elina_dimchange_alloc(0,num_out_pixels)\n",
    "for i in range(num_out_pixels):\n",
    "   dimadd.contents.dim[i] = num_in_pixels\n",
    "elina_abstract0_add_dimensions(man, True, element, dimadd, False)\n",
    "elina_dimchange_free(dimadd)\n",
    "np.ascontiguousarray(weights, dtype=np.double)\n",
    "np.ascontiguousarray(biases, dtype=np.double)\n",
    "var = num_in_pixels\n",
    "# handle affine layer\n",
    "for i in range(num_out_pixels):\n",
    "   tdim= ElinaDim(var)\n",
    "   linexpr0 = analyzer.generate_linexpr0(weights[i],biases[i],num_in_pixels)\n",
    "   element = elina_abstract0_assign_linexpr_array(man, True, element, tdim, linexpr0, 1, None)\n",
    "   var+=1\n",
    "dimrem = elina_dimchange_alloc(0,num_in_pixels)\n",
    "for i in range(num_in_pixels):\n",
    "   dimrem.contents.dim[i] = i\n",
    "elina_abstract0_remove_dimensions(man, True, element, dimrem)\n",
    "elina_dimchange_free(dimrem)\n",
    "\n",
    "mybounds = elina_abstract0_to_box(man, element)\n",
    "\n",
    "for i in range(num_out_pixels):\n",
    "   inf = mybounds[i].contents.inf.contents.val.dbl\n",
    "   sup = mybounds[i].contents.sup.contents.val.dbl\n",
    "   #print(\"----boxRelu----\")\n",
    "   print([inf,sup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = nn.weights[2]\n",
    "biases = nn.biases[2]\n",
    "        \n",
    "num_out_pixels = len(weights)\n",
    "np.ascontiguousarray(weights, dtype=np.double)\n",
    "np.ascontiguousarray(biases, dtype=np.double)\n",
    "        \n",
    "bounds = []\n",
    "# handle linear solver\n",
    "for j in range(10):\n",
    "    bounds.append(linear_solver(inf, sup, weights, biases, j, 10))\n",
    "    \n",
    "\n",
    "bounds = np.array(bounds)\n",
    "inf, sup = bounds[:,0], bounds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_I = range(10) \n",
    "set_J = range(10)\n",
    "\n",
    "set_optimize_I = [i for i in set_I if inf[i]<0 and sup[i]>0] #boxes optimized by linear program\n",
    "set_zeros_I = [i for i in set_I if inf[i]<=0 and sup[i]<=0]  #boxes taken to [0,0] by relu \n",
    "set_leave_I = [i for i in set_I if inf[i]>0 and sup[i]>0] #boxes left as before relu    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_optimize_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_solver(inf, sup, weights, biases, j, num_in_pixels):\n",
    "    \n",
    "    #j is the index of the current output node optimized\n",
    "\n",
    "    set_I = range(num_in_pixels) \n",
    "    set_J = range(num_in_pixels)\n",
    "    \n",
    "\n",
    "    set_optimize_I = [i for i in set_I if inf[i]<0 and sup[i]>0] #boxes optimized by linear program\n",
    "    set_zeros_I = [i for i in set_I if inf[i]<=0 and sup[i]<=0]  #boxes taken to [0,0] by relu \n",
    "    set_leave_I = [i for i in set_I if inf[i]>0 and sup[i]>0] #boxes left as before relu    \n",
    "    \n",
    "    lambda_ = [0]*len(set_I)\n",
    "    for i in set_optimize_I:\n",
    "        lambda_[i] = sup[i]/(sup[i]-inf[i])\n",
    "\n",
    "\n",
    "    mu = [0]*len(set_I)\n",
    "    for i in set_optimize_I:\n",
    "        mu[i] = (-1)*(sup[i]*inf[i])/(sup[i]-inf[i])\n",
    "\n",
    "        \n",
    "    #---------------------------------------\n",
    "    #MINIMIZATION\n",
    "    \n",
    "    opt_model = Model(\"mip1\")\n",
    "    #opt_model.setParam('OutputFlag', False)\n",
    "    h_i_vars  = opt_model.addVars(num_in_pixels, lb=inf, ub=sup, name='h')\n",
    "\n",
    "    relu_h_i_vars  = opt_model.addVars(num_in_pixels, name='relu_h')\n",
    "\n",
    "        # Set objective sum over i wji*relu_h_is\n",
    "    objective = grb.quicksum(weights[j,i] * relu_h_i_vars[i] for i in set_I) + biases[j]\n",
    "\n",
    "        # for minimization\n",
    "    \n",
    "\n",
    "    opt_model.setObjective(objective, GRB.MINIMIZE)\n",
    "\n",
    "    constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.LESS_EQUAL,\n",
    "                                           rhs=lambda_[i] * h_i_vars[i] + mu[i], name=\"constraint_{0}\".format(i))\n",
    "                   for i in set_optimize_I}\n",
    "   \n",
    "        # >= constraints\n",
    "    constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=0, name=\"constraint_{0}\".format(i))\n",
    "                   for i in set_optimize_I}\n",
    "\n",
    "    # >= constraints\n",
    "    constraints = {i :opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=h_i_vars[i], \n",
    "                                          name=\"constraint_{0}\".format(i)) for i in set_optimize_I}\n",
    "        \n",
    "    # == constraints\n",
    "    constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=h_i_vars[i],name=\"constraint_{0}\".format(i)) \n",
    "                   for i in set_leave_I}\n",
    "\n",
    "    constraints = {i : opt_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=0,name=\"constraint_{0}\".format(i)) \n",
    "                  for i in set_zeros_I}\n",
    "\n",
    "    opt_model.setParam('OutputFlag', False)\n",
    "    opt_model.optimize()\n",
    "    #opt_model.computeIIS()\n",
    "    opt_model.write('out1_min.mps')\n",
    "    #opt_model.write('out1.ilp')\n",
    "    h_j_min = opt_model.objVal\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    #MAXIMIZATION  \n",
    "\n",
    "    max_model = Model(\"max\")\n",
    "    \n",
    "    #opt_model.setParam('OutputFlag', False)\n",
    "    h_i_vars  = max_model.addVars(num_in_pixels, lb=inf, ub=sup, name='h')\n",
    "\n",
    "    relu_h_i_vars  = max_model.addVars(num_in_pixels, lb=0.0, ub=GRB.INFINITY, name='relu_h')\n",
    "\n",
    "        # Set objective sum over i wji*relu_h_is\n",
    "    objective = grb.quicksum(weights[j,i] * relu_h_i_vars[i]for i in set_I) + biases[j]\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    max_model.setObjective(objective, GRB.MAXIMIZE)\n",
    "\n",
    "    constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.LESS_EQUAL,\n",
    "                                           rhs=lambda_[i] * h_i_vars[i] + mu[i], name=\"constraint_{0}\".format(i))\n",
    "                   for i in set_optimize_I}\n",
    "    \n",
    "    # >= constraints\n",
    "    constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=0, name=\"constraint_{0}\".format(i))\n",
    "                   for i in set_optimize_I}\n",
    "\n",
    "    # >= constraints\n",
    "    constraints = {i :max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.GREATER_EQUAL,rhs=h_i_vars[i], \n",
    "                                          name=\"constraint_{0}\".format(i)) for i in set_optimize_I}\n",
    "  \n",
    "    # == constraints\n",
    "    constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=h_i_vars[i],name=\"constraint_{0}\".format(i)) \n",
    "                   for i in set_leave_I}\n",
    "\n",
    "\n",
    "    constraints = {i : max_model.addConstr(lhs=relu_h_i_vars[i],sense=grb.GRB.EQUAL,rhs=0,name=\"constraint_{0}\".format(i)) \n",
    "                  for i in set_zeros_I}\n",
    "\n",
    "    max_model.setParam('OutputFlag',False)\n",
    "    max_model.optimize()\n",
    "    #max_model.computeIIS()\n",
    "    max_model.write('out_max.mps')\n",
    "    #max_model.write('out1.ilp')\n",
    "    \n",
    "    h_j_max = max_model.objVal\n",
    "    \n",
    "    return h_j_min, h_j_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
